{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install -U \"langchain==0.0.344\" openai tiktoken lark datasets sentence_transformers FlagEmbedding lancedb -qq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import LanceDB\n",
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "\n",
    "#Text Splitting\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.storage import InMemoryStore\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "import lancedb\n",
    "from dotenv import dotenv_values\n",
    "import openai\n",
    "\n",
    "env_vars = dotenv_values('.env')\n",
    "openai.api_key = \"sk-proj-Tzc9mrWyEFVxyDsq5HiWT3BlbkFJxp47toOztG4XRILBeRxr\"\n",
    "\n",
    "# Embedding Functions\n",
    "# model_name = \"BAAI/bge-small-en-v1.5\" # Open Source and effective Embedding\n",
    "# encode_kwargs = {'normalize_embeddings': True} # set True to compute cosine similarity\n",
    "# bge_embeddings = HuggingFaceBgeEmbeddings(model_name=model_name,model_kwargs={'device': 'cuda'},encode_kwargs=encode_kwargs)\n",
    "bge_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\", openai_api_key=openai.api_key)\n",
    "# Data Chunking Functions\n",
    "small_chunk_splitter = RecursiveCharacterTextSplitter(chunk_size = 512) # Splitter to split documents into small chunks\n",
    "big_chunk_splitter = RecursiveCharacterTextSplitter(chunk_size=2048) # Another Level of Bigger Chunks\n",
    "\n",
    "# Lance DB Connection. Load if exists else create\n",
    "my_db = lancedb.connect(\"./my_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk-proj-Tzc9mrWyEFVxyDsq5HiWT3BlbkFJxp47toOztG4XRILBeRxr\n"
     ]
    }
   ],
   "source": [
    "print(openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ArrowInvalid",
     "evalue": "list_size needs to be a strict positive integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowInvalid\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m\n\u001b[1;32m      5\u001b[0m docs \u001b[38;5;241m=\u001b[39m [Document(page_content\u001b[38;5;241m=\u001b[39mcontent, doc_id \u001b[38;5;241m=\u001b[39m _id, metadata \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoc_id\u001b[39m\u001b[38;5;124m\"\u001b[39m:_id}) \u001b[38;5;28;01mfor\u001b[39;00m (_id, content) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(long_texts)] \u001b[38;5;66;03m# List of LangChain Document Objects\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# if \"small_chunk_table\" in my_db.table_names():\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#   small_chunk_table = my_db.open_table(\"small_chunk_table\")\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# else: # NOTE: 384 is the size of BAAI Embedding and -999 because it's a dummy data so invalid Embedding\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m small_chunk_table \u001b[38;5;241m=\u001b[39m \u001b[43mmy_db\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msmall_chunk_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvector\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdoc_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m-1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moverwrite\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# small_chunk_table.delete('doc_id = \"-1\"')\u001b[39;00m\n\u001b[1;32m     15\u001b[0m vectorstore \u001b[38;5;241m=\u001b[39m LanceDB(small_chunk_table, bge_embeddings) \u001b[38;5;66;03m# Vectorstore to use to index the child chunks\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lancedb/db.py:418\u001b[0m, in \u001b[0;36mLanceDBConnection.create_table\u001b[0;34m(self, name, data, schema, mode, exist_ok, on_bad_vectors, fill_value, embedding_functions)\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode must be either \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moverwrite\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    416\u001b[0m validate_table_name(name)\n\u001b[0;32m--> 418\u001b[0m tbl \u001b[38;5;241m=\u001b[39m \u001b[43mLanceTable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    419\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexist_ok\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_bad_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_bad_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    426\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    427\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43membedding_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    428\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tbl\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lancedb/table.py:1518\u001b[0m, in \u001b[0;36mLanceTable.create\u001b[0;34m(cls, db, name, data, schema, mode, exist_ok, on_bad_vectors, fill_value, embedding_functions)\u001b[0m\n\u001b[1;32m   1515\u001b[0m     metadata \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mget_table_metadata(embedding_functions)\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_bad_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_bad_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1523\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1524\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1526\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m schema \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lancedb/table.py:125\u001b[0m, in \u001b[0;36m_sanitize_data\u001b[0;34m(data, schema, metadata, on_bad_vectors, fill_value)\u001b[0m\n\u001b[1;32m    123\u001b[0m         metadata\u001b[38;5;241m.\u001b[39mupdate(data\u001b[38;5;241m.\u001b[39mschema\u001b[38;5;241m.\u001b[39mmetadata \u001b[38;5;129;01mor\u001b[39;00m {})\n\u001b[1;32m    124\u001b[0m         data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mreplace_schema_metadata(metadata)\n\u001b[0;32m--> 125\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[43m_sanitize_schema\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschema\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_bad_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_bad_vectors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\n\u001b[1;32m    127\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, Iterable):\n\u001b[1;32m    129\u001b[0m     data \u001b[38;5;241m=\u001b[39m _to_record_batch_generator(\n\u001b[1;32m    130\u001b[0m         data, schema, metadata, on_bad_vectors, fill_value\n\u001b[1;32m    131\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lancedb/table.py:1774\u001b[0m, in \u001b[0;36m_sanitize_schema\u001b[0;34m(data, schema, on_bad_vectors, fill_value)\u001b[0m\n\u001b[1;32m   1772\u001b[0m \u001b[38;5;66;03m# just check the vector column\u001b[39;00m\n\u001b[1;32m   1773\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m VECTOR_COLUMN_NAME \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mcolumn_names:\n\u001b[0;32m-> 1774\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_sanitize_vector_column\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1775\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1776\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvector_column_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mVECTOR_COLUMN_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1777\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_bad_vectors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_bad_vectors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1778\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1779\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1781\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lancedb/table.py:1820\u001b[0m, in \u001b[0;36m_sanitize_vector_column\u001b[0;34m(data, vector_column_name, on_bad_vectors, fill_value)\u001b[0m\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m pa\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mis_fixed_size_list(vec_arr\u001b[38;5;241m.\u001b[39mtype):\n\u001b[1;32m   1818\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported vector column type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvec_arr\u001b[38;5;241m.\u001b[39mtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1820\u001b[0m vec_arr \u001b[38;5;241m=\u001b[39m \u001b[43mensure_fixed_size_list\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvec_arr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1821\u001b[0m data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mset_column(\n\u001b[1;32m   1822\u001b[0m     data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;241m.\u001b[39mindex(vector_column_name), vector_column_name, vec_arr\n\u001b[1;32m   1823\u001b[0m )\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;66;03m# Use numpy to check for NaNs, because as pyarrow 14.0.2 does not have `is_nan`\u001b[39;00m\n\u001b[1;32m   1826\u001b[0m \u001b[38;5;66;03m# kernel over f16 types.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/lancedb/table.py:1844\u001b[0m, in \u001b[0;36mensure_fixed_size_list\u001b[0;34m(vec_arr)\u001b[0m\n\u001b[1;32m   1842\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1843\u001b[0m     list_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(values) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(vec_arr)\n\u001b[0;32m-> 1844\u001b[0m vec_arr \u001b[38;5;241m=\u001b[39m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFixedSizeListArray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlist_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vec_arr\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/array.pxi:2682\u001b[0m, in \u001b[0;36mpyarrow.lib.FixedSizeListArray.from_arrays\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/error.pxi:154\u001b[0m, in \u001b[0;36mpyarrow.lib.pyarrow_internal_check_status\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pyarrow/error.pxi:91\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mArrowInvalid\u001b[0m: list_size needs to be a strict positive integer"
     ]
    }
   ],
   "source": [
    "# Load a sample data here\n",
    "long_texts = load_dataset(\"huggingartists/eminem\")[\"train\"].to_pandas().sample(100)[\"text\"] # Data of huge context length. Use 100 random examples for demo\n",
    "\n",
    "# Convert to LangChain Document object\n",
    "docs = [Document(page_content=content, doc_id = _id, metadata = {\"doc_id\":_id}) for (_id, content) in enumerate(long_texts)] # List of LangChain Document Objects\n",
    "\n",
    "\n",
    "# if \"small_chunk_table\" in my_db.table_names():\n",
    "#   small_chunk_table = my_db.open_table(\"small_chunk_table\")\n",
    "# else: # NOTE: 384 is the size of BAAI Embedding and -999 because it's a dummy data so invalid Embedding\n",
    "small_chunk_table = my_db.create_table(\"small_chunk_table\", data=[{\"vector\": [], \"text\": \"\", \"doc_id\": \"-1\",}], mode=\"overwrite\")\n",
    "\n",
    "# small_chunk_table.delete('doc_id = \"-1\"')\n",
    "\n",
    "vectorstore = LanceDB(small_chunk_table, bge_embeddings) # Vectorstore to use to index the child chunks\n",
    "store = InMemoryStore() # The storage layer for the parent documents\n",
    "\n",
    "full_doc_retriever = ParentDocumentRetriever(vectorstore=vectorstore, docstore=store, child_splitter=small_chunk_splitter)\n",
    "\n",
    "full_doc_retriever.add_documents(docs, ids=None) # Add all the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(bge_embeddings.embed_query(\"test\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch 3 most similar Smaller Documents\n",
    "sub_docs = vectorstore.similarity_search(\"I am whatever you say I am and if I wasn't why would you say I am\", k=3)\n",
    "\n",
    "print(sub_docs[0].page_content) # This is a Smaller Chunk.\n",
    "\n",
    "\n",
    "full_docs = full_doc_retriever.get_relevant_documents(\"I am whatever you say I am and if I wasn't why would you say I am\", k = 3)\n",
    "print(full_docs[0].page_content) # This is the Parent Document returned after matching the smaller chunks internally"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

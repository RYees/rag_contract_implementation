{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get local db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "import os\n",
    "import openai\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "\n",
    "env_vars = dotenv_values('.env')\n",
    "openai.api_key = env_vars.get('OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "rpath = os.path.abspath('..')\n",
    "if rpath not in sys.path:\n",
    "    sys.path.insert(0, rpath)\n",
    "\n",
    "import utils.chroma as chom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/sec.pdf'\n",
    "pdftexts = chom.pdf_reader(file_path)\n",
    "# pdftexts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x7208ec2999c0>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x7208eebb9ff0>, model='text-embedding-3-small', deployment='text-embedding-ada-002', openai_api_version='', openai_api_base=None, openai_api_type='', openai_proxy='', embedding_ctx_length=8191, openai_api_key='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', openai_organization=None, allowed_special=set(), disallowed_special='all', chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "# embedded_documents = []\n",
    "# for code_content in pdftexts:\n",
    "#     embedded_document = embeddings.embed_documents([code_content])\n",
    "#     embedded_documents.append(embedded_document)\n",
    "\n",
    "# embeddings\n",
    "vectordb= Chroma(embedding_function=embeddings, collection_name=\"core\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are going to do a Naive RAG.\n",
    "\n",
    "## Remember:\n",
    "\n",
    "- R -> Retrieval\n",
    "- A -> Augmented\n",
    "- G -> Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x7208ef1ff220>, search_kwargs={'k': 10})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retriever = vectordb.as_retriever(search_kwargs={ \"k\" : 10})\n",
    "\n",
    "# Similarity score threshold retrieval\n",
    "# naive_retriever = db.as_retriever(search_kwargs={\"score_threshold\": 0.8}, search_type=\"similarity_score_threshold\")\n",
    "\n",
    "# Maximum marginal relevance retrieval\n",
    "# naive_retriever = db.as_retriever(search_type=\"mmr\")\n",
    "naive_retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "TEMPLATE = \"\"\"\\\n",
    "You are happy assistant. Use the context provided below to answer the question.\n",
    "\n",
    "Answer question in summarization, in one line of sentence. \n",
    "\n",
    "If you do not know the answer, or are unsure, say you don't know.\n",
    "\n",
    "Query:\n",
    "{question}\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = ChatPromptTemplate.from_template(TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_models import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finally, we are going to create a Rag Chain. For that, we are going to use LCEL (LangChain Expression Language)\n",
    "If you want to learn more about LCEL, check this good tutorial: https://www.youtube.com/watch?v=O0dUOtOIrfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The simplest way to use LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sellers are typically responsible for a breach of representations and warranties to the extent outlined in the sales agreement.'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": RunnablePassthrough(), \"context\": naive_retriever })\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "naive_retrieval_chain = setup_and_retrieval | rag_prompt | chat_model | output_parser\n",
    "\n",
    "\n",
    "naive_retrieval_chain.invoke(\"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "question = \"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\"\n",
    "retrieval_input = [{'context': 'Your retrieval context goes here'}, {'context': 'Another retrieval context goes here'}]\n",
    "\n",
    "# Define a retriever function that accepts a list as input\n",
    "def retrieve_fn(inputs):\n",
    "    return inputs  # Return the input list as is\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": RunnablePassthrough(), \"context\": retrieve_fn})\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "retrieval_chain = setup_and_retrieval | rag_prompt | chat_model | output_parser\n",
    "\n",
    "output = retrieval_chain.invoke({\"question\": question, \"context\": retrieval_input})\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_retrieval_chain.invoke(\"In what situation does the Sellers have liability for breach of representations and warranties?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little more complex to use LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sellers are responsible for breach of representations and warranties if the representations are untrue or warranties are not fulfilled; extent of responsibility depends on the specific terms of the agreement.'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": itemgetter(\"question\") |  RunnablePassthrough(), \"context\": itemgetter(\"question\") |  naive_retriever })\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "naive_retrieval_chain = setup_and_retrieval | rag_prompt | chat_model | output_parser\n",
    "\n",
    "\n",
    "naive_retrieval_chain.invoke({\"question\" : \"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little X2 more complex to use LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Sellers are responsible for a breach of representations and warranties when the statements made are false or misleading, to the extent outlined in the contract.'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": itemgetter(\"question\") |  RunnablePassthrough(), \"context\": itemgetter(\"question\") }) | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "\n",
    "naive_retrieval_chain = setup_and_retrieval | rag_prompt | chat_model | output_parser\n",
    "\n",
    "\n",
    "naive_retrieval_chain.invoke({\"question\" : \"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A little X3 more complex to use LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': AIMessage(content='Sellers are responsible for breach of representations and warranties if they are proven to have knowingly provided false information, and the extent of their responsibility can vary based on the specifics of the situation.', response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 61, 'total_tokens': 98}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-aef70a5a-03b0-4e70-b2d9-ce32d59442de-0'),\n",
       " 'context': []}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "from operator import itemgetter\n",
    "\n",
    "setup_and_retrieval = RunnableParallel({\"question\": itemgetter(\"question\") |  RunnablePassthrough(), \"context\": itemgetter(\"question\") | naive_retriever }) | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "\n",
    "naive_retrieval_chain = setup_and_retrieval | {\"response\": rag_prompt | chat_model, \"context\": itemgetter(\"context\")}\n",
    "\n",
    "\n",
    "naive_retrieval_chain.invoke({\"question\" : \"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': AIMessage(content='Sellers are responsible for a breach of representations and warranties when they provide inaccurate or false information about the product or service being sold. The extent of their responsibility depends on the terms outlined in the contract.', response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 61, 'total_tokens': 101}, 'model_name': 'gpt-3.5-turbo', 'system_fingerprint': 'fp_3b956da36b', 'finish_reason': 'stop', 'logprobs': None}, id='run-7aeaaf76-8da5-48e6-82c0-72d703c66575-0'),\n",
       " 'context': []}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_retrieval_chain.invoke({\"question\" : \"Under what circumstances and to what extent the Sellers are responsible for a breach of representations and warranties?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

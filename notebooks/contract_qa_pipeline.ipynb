{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VZ3C2G0zzaWp",
        "sdkxspGrpUfG",
        "VT_-VYdhwADN",
        "OoV7-NH3wUFu",
        "ZvkGMOgZwfG2",
        "Kyqbkub7yByt",
        "Gx88NQTh1ZUL",
        "mUdknhHf2deL",
        "6Wj5Q66o5L6K"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Prepare The Environment\n"
      ],
      "metadata": {
        "id": "VZ3C2G0zzaWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  docx2txt\n",
        "!pip install --quiet unstructured"
      ],
      "metadata": {
        "id": "pkw4MSTCv9-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade langchain\n",
        "!pip install langchain_openai\n",
        "!pip install chromadb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3fzd-Q6bzwoa",
        "outputId": "899c968b-cf31-4d5b-fba0-c56307196b52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.9)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.27)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.21 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.22)\n",
            "Requirement already satisfied: langchain-core<0.2,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.26)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.5)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.26->langchain) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2,>=0.1.26->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.0.7)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.26 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.26)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.25.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.12.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (0.1.5)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.6.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.26->langchain_openai) (8.2.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.10.0->langchain_openai) (4.9.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.5.2->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.26->langchain_openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (1.0.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.10.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.26->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.26->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-core<0.2.0,>=0.1.26->langchain_openai) (2.0.7)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.4.23)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.0.3)\n",
            "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.6.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.109.2)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.25.2)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.2)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.9.0)\n",
            "Requirement already satisfied: pulsar-client>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.4.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.17.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.43b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.22.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.2)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.2)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.60.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.2)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (29.0.0)\n",
            "Requirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
            "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.9.14)\n",
            "Requirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.36.3)\n",
            "Requirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2024.2.2)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (6.11.0)\n",
            "Requirement already satisfied: backoff<3.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.22.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.22.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.22.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.43b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.43b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.43b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.43b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.43b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.7.2)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.16.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.21.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (3.7.1)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.37.0,>=0.36.3->fastapi>=0.95.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXdjIp8B0NDq",
        "outputId": "0190a661-f5f7-48e1-b83a-834c1f2e2aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQq_L5Dix9Gd"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "OPEN_AI_KEY= userdata.get('OPENAI_KEY')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 LangChain Q&A over Documents - Streamlined\n",
        "\n",
        "Example: A tool that would allow you to query a product catalog for items of interest."
      ],
      "metadata": {
        "id": "0ACIb7xx0Fg6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from IPython.display import display, Markdown\n",
        "from langchain_openai import OpenAI"
      ],
      "metadata": {
        "id": "YCBvgP2Z2qYw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are using Langchain mostly:\n",
        "\n",
        "- Manual: https://api.python.langchain.com/en/stable/langchain_api_reference.html\n",
        "- Documentation: https://python.langchain.com/docs/modules/data_connection/"
      ],
      "metadata": {
        "id": "4smX9cTtAm7G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Loading and chunking the data"
      ],
      "metadata": {
        "id": "-l39pF3Jkrbu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# document\n",
        "file = \"/content/drive/MyDrive/notes/week11/data/Raptor Contract.docx.txt\""
      ],
      "metadata": {
        "id": "RZDuXAGO_PpX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(file, \"r\", encoding=\"utf-8\") as f:\n",
        "  # Read the contents of the file\n",
        "  file_contents = f.read()"
      ],
      "metadata": {
        "id": "lihYIHajwbFC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(file_contents)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRjdgDI-UZyC",
        "outputId": "231ab919-c128-476d-8f7f-73d498065ba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Language models have a token limit which we should not exceed. When we split the text into chunks, we want do so counting the number of tokens instead of characters.\n",
        "It is better to count tokens using the same tokenizer as used in the language model.\n",
        "Because we will use OpenAI later, here we'll use [tiktoken](https://github.com/openai/tiktoken), a fast BPE tokenizer created by OpenAI.\n",
        "\n",
        "- How the text is split: recursively, by characters passed in.\n",
        "- How the chunk size is measured: by tiktoken tokenizer."
      ],
      "metadata": {
        "id": "PhRfIil_znbV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade --quiet  tiktoken"
      ],
      "metadata": {
        "id": "zLQnitCi1Tvu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.text_splitter import TokenTextSplitter\n",
        "\n",
        "def text_splitter_chunks(doc: str):\n",
        "  text_splitter = RecursiveCharacterTextSplitter(\n",
        "      separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"],\n",
        "      chunk_size=1000, # checking here https://chunkviz.up.railway.app/ .. it seems optimal 700-1000 char\n",
        "      chunk_overlap=0,\n",
        "      length_function=len,\n",
        "      is_separator_regex=False,\n",
        "  )\n",
        "\n",
        "  docs = text_splitter.create_documents([doc])\n",
        "  return docs\n",
        "\n",
        "# Look up encoding_name for tiktoken used in TokenTextSpliter here:\n",
        "# https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
        "# \"cl100k_base\" for models \"gpt-4\", \"gpt-3.5-turbo\", \"text-embedding-ada-002\",  and others.\n",
        "\n",
        "def tiktoken_textsplitter(character_split_texts):\n",
        "    token_splitter = TokenTextSplitter(encoding_name='cl100k_base', chunk_overlap=0, chunk_size=256) # uses tiktoken by default\n",
        "    # token_split_texts = []\n",
        "    # for text in character_split_texts:\n",
        "    #     token_split_texts += token_splitter.split_text(text.page_content)\n",
        "    token_split_texts = token_splitter.split_documents(character_split_texts)\n",
        "    return token_split_texts"
      ],
      "metadata": {
        "id": "w9OvtoXz1z1H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = text_splitter_chunks(file_contents)\n",
        "print(f\"Number of chunks after recursive chunking is {len(docs)}\")\n",
        "docs = tiktoken_textsplitter(docs)\n",
        "print(f\"Final number of chunks is {len(docs)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OBHzzvoXfP8W",
        "outputId": "c4dfe553-07b6-4dcf-c449-2caf5bdfc001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of chunks after recursive chunking is 357\n",
            "Final number of chunks is 361\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FOTaP7Z9afmv",
        "outputId": "eb97cf7b-59dc-43b0-dec0-4ef1952f07b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='\\ufeffSTOCK PURCHASE AGREEMENT\\nBY AND AMONG\\n[BUYER],\\n[TARGET COMPANY],\\nTHE SELLERS LISTED ON SCHEDULE I HERETO\\nAND\\nTHE SELLERS’ REPRESENTATIVE NAMED HEREIN\\nDated as of [●]\\n\\n\\n[This document is intended solely to facilitate discussions among the parties identified herein.  Neither this document nor such discussions are intended to create, nor will either or both be deemed to create, a legally binding or enforceable offer or agreement of any type or nature, unless and until a definitive written agreement is executed and delivered by each of the parties hereto.\\n\\n\\nThis document shall be kept confidential pursuant to the terms of the Confidentiality Agreement entered into by the parties and, if applicable, its affiliates with respect to the subject matter hereof.]')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 2: Vector Store**\n",
        "\n",
        "here we use an in-memory vector store, that does not need to connect to an external database. Simple for start example."
      ],
      "metadata": {
        "id": "XA3bULEUJEUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.indexes import VectorstoreIndexCreator"
      ],
      "metadata": {
        "id": "ifZVjQ0MJSbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the embedding used by vector store\n",
        "# if we set OPEN_AI_KEY environment variable, we won't need to explicitly define the embedding\n",
        "# because the VectorstoreIndexCreator used OpenAIEmbeddings by default\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings_model = OpenAIEmbeddings(openai_api_key=OPEN_AI_KEY)"
      ],
      "metadata": {
        "id": "cTGojLnPNs9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "db = Chroma.from_documents(docs, embeddings_model)"
      ],
      "metadata": {
        "id": "iTwtZT91hLzh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Important: We can use this vector store to fine \"chunks\" similar to any text\n",
        "\n",
        "# an example query\n",
        "\n",
        "query = \" How much is the escrow amount?\"\n",
        "\n",
        "similar_docs = db.similarity_search(query, k=5) # returns the 5 most similar docs, default is 4"
      ],
      "metadata": {
        "id": "zDbaz7iVhiq4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "similar_docs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Chb_ZF6kiuL5",
        "outputId": "669ccb37-a634-4c56-de2d-1d1c59ef8aba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content='3. Escrow.'),\n",
              " Document(page_content='3. Escrow.'),\n",
              " Document(page_content='1. At Closing, Buyer will deposit the Escrow Amount in escrow on behalf of the Sellers in accordance with the Escrow Agreement.  The Escrow Amount shall be held and, subject to Section 2.07, released to the Company Securityholders in accordance with the provisions of the Escrow Agreement with the Company Securityholders being entitled to share in such released amounts in accordance with their Pro Rata Percentages'),\n",
              " Document(page_content='1. At Closing, Buyer will deposit the Escrow Amount in escrow on behalf of the Sellers in accordance with the Escrow Agreement.  The Escrow Amount shall be held and, subject to Section 2.07, released to the Company Securityholders in accordance with the provisions of the Escrow Agreement with the Company Securityholders being entitled to share in such released amounts in accordance with their Pro Rata Percentages'),\n",
              " Document(page_content='final Purchase Price shall be paid to the Buyer, or its designee, in accordance with the terms of the Escrow Agreement (and any remaining balance of the Escrow Amount not required to be paid to the Buyer shall be released to Company Securityholders in accordance with the terms of the Escrow Agreement).')]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define the retriever\n",
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "bGniJ3xwh6Y_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # indexCreator helps us create a vector store easily. What is the role of indexer?\n",
        "\n",
        "# index = VectorstoreIndexCreator(\n",
        "#     vectorstore_cls=Chroma,\n",
        "#     embedding= embeddings_model # OpenAIEmbeddings is the default, see note above\n",
        "# ).from_documents(docs)"
      ],
      "metadata": {
        "id": "Tg24lLxU__Mj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 3: choose an llm**"
      ],
      "metadata": {
        "id": "atjR40GXQc1u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm_model_name = 'gpt-3.5-turbo-instruct'\n",
        "llm_model = OpenAI(temperature=0.0, model=llm_model_name, openai_api_key= OPEN_AI_KEY)"
      ],
      "metadata": {
        "id": "bdfELCdsQtaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "setting temperature = 0, reduces randomness. This is because we want our generative model to be precise and fact-based (on provided documents), instead of creative."
      ],
      "metadata": {
        "id": "hsDuds7HM59r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**step 4: Combine vector store + llm and query it**"
      ],
      "metadata": {
        "id": "Ht8Gnx-bTSNS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# an example query\n",
        "\n",
        "query = \" How much is the escrow amount?\""
      ],
      "metadata": {
        "id": "SReaLgIRNJ7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa_stuff = RetrievalQA.from_chain_type(\n",
        "    llm=llm_model,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever,\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "id": "XODPNDJ3ifIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain\n",
        "langchain.debug = True"
      ],
      "metadata": {
        "id": "qR_sw0RMUAM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = qa_stuff.invoke(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhNRqd_gieaF",
        "outputId": "6626e2dc-8294-4ca3-84b3-3e72fa9f03f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"query\": \" How much is the escrow amount?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \" How much is the escrow amount?\",\n",
            "  \"context\": \"3. Escrow.\\n\\n3. Escrow.\\n\\n1. At Closing, Buyer will deposit the Escrow Amount in escrow on behalf of the Sellers in accordance with the Escrow Agreement.  The Escrow Amount shall be held and, subject to Section 2.07, released to the Company Securityholders in accordance with the provisions of the Escrow Agreement with the Company Securityholders being entitled to share in such released amounts in accordance with their Pro Rata Percentages\\n\\n1. At Closing, Buyer will deposit the Escrow Amount in escrow on behalf of the Sellers in accordance with the Escrow Agreement.  The Escrow Amount shall be held and, subject to Section 2.07, released to the Company Securityholders in accordance with the provisions of the Escrow Agreement with the Company Securityholders being entitled to share in such released amounts in accordance with their Pro Rata Percentages\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n3. Escrow.\\n\\n3. Escrow.\\n\\n1. At Closing, Buyer will deposit the Escrow Amount in escrow on behalf of the Sellers in accordance with the Escrow Agreement.  The Escrow Amount shall be held and, subject to Section 2.07, released to the Company Securityholders in accordance with the provisions of the Escrow Agreement with the Company Securityholders being entitled to share in such released amounts in accordance with their Pro Rata Percentages\\n\\n1. At Closing, Buyer will deposit the Escrow Amount in escrow on behalf of the Sellers in accordance with the Escrow Agreement.  The Escrow Amount shall be held and, subject to Section 2.07, released to the Company Securityholders in accordance with the provisions of the Escrow Agreement with the Company Securityholders being entitled to share in such released amounts in accordance with their Pro Rata Percentages\\n\\nQuestion:  How much is the escrow amount?\\nHelpful Answer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:OpenAI] [505ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \" The escrow amount is not specified in the given context. It would depend on the specific agreement between the Buyer and Sellers.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"completion_tokens\": 25,\n",
            "      \"total_tokens\": 259,\n",
            "      \"prompt_tokens\": 234\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [507ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \" The escrow amount is not specified in the given context. It would depend on the specific agreement between the Buyer and Sellers.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [512ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output_text\": \" The escrow amount is not specified in the given context. It would depend on the specific agreement between the Buyer and Sellers.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [809ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"result\": \" The escrow amount is not specified in the given context. It would depend on the specific agreement between the Buyer and Sellers.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The RAG fails at answering the question, the issue for now seems to be that the retriever is failing at retrieving the relevant docs.\n",
        "\n",
        "The issue actually seems to be the chunking."
      ],
      "metadata": {
        "id": "VuXUp_rcjO2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3 LangChain Q&A over Documents - Step by step\n",
        "\n",
        "General Idea: The goal is to combine llm with documents. Issue is that LLMs have limited \"context window\", which cannot fit large documents.\n",
        "\n",
        "Embedding: a numeric representation of text, that encode the semantic meaning of the text. Similar text will have similar embedding vectors (cosine similarity).\n",
        "\n",
        "Vector Store: a way to store embedding vectors. It is populated with \"chunks\" of text from the documents.\n",
        "why chunks, and not the whole documents?\n",
        "These chunks are what is going to be passed to the LLM later, they have to be small enough to fit the LLM's context window.\n",
        "\n",
        "Each chunk -> embedding vector -> stored in Vector DB\n",
        "\n",
        "Query -> embedding vector of query -> compared to vectors in Vector DB -> returns most relevant vectors -> passed to LLM with query\n",
        "\n"
      ],
      "metadata": {
        "id": "sdkxspGrpUfG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Define the Retriever\n",
        "\n",
        "A retriever is defined as a generic interface that takes a query and returns documents. It can be underpinned by any method that achieves this: Vector store is just one example of such methods. there are other methods, less advanced and more advanced than a vector store."
      ],
      "metadata": {
        "id": "Gx88NQTh1ZUL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = db.as_retriever()"
      ],
      "metadata": {
        "id": "G4Kpbr4uzoM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step : Use a retriever chain instead\n",
        "\n",
        "important choose a retriever **chain type**:\n",
        "*I think chain type refers to how the prompt is created from query and retrieved documents.*\n",
        "1. Stuff method: here we use chain_type=\"stuff\", the simplest, which stuff all relevant docs into the context.\n",
        "   - pros: makes 1 call to LLM\n",
        "   - cons: issues with context window if retrieved many or large docs\n",
        "2. Map_reduce: pass each retrieved chunk + query to the LLM seperately. Then pass all the outputs back to the LLM to be summarized.\n",
        "   - pros: takes any number of retrieved docs. parallelizable\n",
        "   - cons: makes many calls to the LLM (expensive). treats all retrived docs as **independent**, which might not be the case.\n",
        "\n",
        "3. refine: works recursively. It passes query + 1 chunk to LLM, then pass the output of the previous step + query + another chunk to LLM .. and so on.\n",
        "   - pros: lead to longer answers (pro or con?)\n",
        "   - cons: takes longer time. not parallelizable. makes many calls to LLM.\n",
        "4. map_rerank [more experimental]: similar to map_reduce, but here with each call to the LLM, you ask the LLM to return a score (eg: tell LLM to score on relevance).\n",
        "   - pros: calls are independent and can be batched, relatively fast.\n",
        "   - cons: makes many call to the LLM."
      ],
      "metadata": {
        "id": "6Wj5Q66o5L6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4 Evaluation\n",
        "Outline:\n",
        "- Example generation\n",
        "- Manual evaluation (and debuging)\n",
        "- LLM-assisted evaluation\n",
        "- LangChain evaluation platform"
      ],
      "metadata": {
        "id": "PMgoYQ9qEeZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 The difficulity of Evaluating RAGs (particularly LLM)"
      ],
      "metadata": {
        "id": "fJIy_IxlNzlS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When creating a QA RAG systems, we will want to evaluate its performance using an evaluation metric (like accuracy). Actually, especially while developing the system, we might want to measure the performance repreatedly (and automatically?), after any modification instroduced into the system.\n",
        "- We can check things by eye: run a test case through the pipeline and judge the result ourselves. However this is limiting.\n",
        "  - Doing repeated tests will be time-consuming and inconvenient\n",
        "  - We can easily check final result, but it won't be as easy to check the intermidiate steps; eg: is the doc retrieved correct?\n",
        "- Comparing result of a RAG to ground truth include comparing strings for semantic matching.\n",
        "  - For example: suppose we ask our RAG to answer this question \"Does the Earth have one moon?\". Ground truth: \"Yes\". RAG's prediction: \"The earth does have one moon\". The 2 answers are equivelant, the RAG got it right. However, the strings of the prediction and the truth don't match exactly, they don't even have a high similarity, they are completely different..even though, in this particular context, they mean the same thing (because they don't mean the same thing generally, they won't have a high cosine similarity).\n",
        "\n",
        "\n",
        "Frameworks and tools that help evaluating LLM based applications:\n",
        "- Viualizers and debuggers: help see what is going on\n",
        "  - setting `langchain.debug = True`\n",
        "\n",
        "\n",
        "> The difficulty in comparing strings is what makes evaluating LLMs hard in the first place. LLMs are used to do really open-ended tasks, generating text, which haven't been done before. Until recently, models weren't good enough to do them. Hence, a lot of evaluation metrics that existed so far aren't good enough. So, we're having to invent new ones, with new heuristics. One of the most popular heuristics is using an LLM to do the evaluation."
      ],
      "metadata": {
        "id": "pE26APJ1R30b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 The RAG we will use"
      ],
      "metadata": {
        "id": "SWt6LPr9Ny7o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We are going to use the same QA retriver chain from section 1\n",
        "\n",
        "# import needed libraries\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import CSVLoader\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain.indexes import VectorstoreIndexCreator\n",
        "from langchain_openai import OpenAI\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "# Data Source\n",
        "file = \"/content/drive/MyDrive/notes/week11/apparel_modified.csv\"\n",
        "loader = CSVLoader(file_path =file)\n",
        "data = loader.load()\n",
        "\n",
        "# Embedding\n",
        "embeddings_model = OpenAIEmbeddings(openai_api_key=OPEN_AI_KEY)\n",
        "\n",
        "# Retriever: Populate VectorStore\n",
        "index = VectorstoreIndexCreator(\n",
        "    vectorstore_cls=Chroma,\n",
        "    embedding= embeddings_model # OpenAIEmbeddings is the default, see note above\n",
        ").from_loaders([loader])\n",
        "\n",
        "# Generator\n",
        "llm_model_name = 'gpt-3.5-turbo-instruct'\n",
        "llm_model = OpenAI(temperature=0.0, model=llm_model_name, openai_api_key= OPEN_AI_KEY)\n",
        "\n",
        "\n",
        "# Chain:  chain_type= stuff\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm_model,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=index.vectorstore.as_retriever(),\n",
        "    verbose=True,\n",
        "    chain_type_kwargs = {\n",
        "        \"document_separator\": \"<<<<>>>>>\"\n",
        "    }\n",
        ")"
      ],
      "metadata": {
        "id": "sFmops357IWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Generating Test Examples"
      ],
      "metadata": {
        "id": "3RH9p-vbLhB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# coming up with test data points\n",
        "data[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jNrLvtw9P5qs",
        "outputId": "4f1945c6-2a84-4a2b-afcf-b8ac49f29596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=\": 12\\nname: Zipped Jacket\\ndescription: Dark navy and light blue men's zipped waterproof jacket with an outer zipped chestpocket for easy storeage.\", metadata={'source': '/content/drive/MyDrive/notes/week11/apparel_modified.csv', 'row': 10})"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[11]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "homgbBwRP_Ge",
        "outputId": "6dd9ba69-4170-413b-c685-df7053ce964f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=': 13\\nname: Silk Summer Top\\ndescription: Silk womens top with short sleeves and number pattern.', metadata={'source': '/content/drive/MyDrive/notes/week11/apparel_modified.csv', 'row': 11})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.1 Hard-coded Examples\n",
        "\n",
        "make up a couple of question-answer pairs ourselves"
      ],
      "metadata": {
        "id": "CMEikdQcRS_m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hardcoded_examples = [\n",
        "    {\n",
        "        \"query\": \"Does the Zipped Jacket have a chestpocket?\",\n",
        "        \"answer\": \"Yes.\"\n",
        "    },\n",
        "    {\n",
        "        \"query\": \"What kind of sleeves does the Silk Summer Top have?\",\n",
        "        \"answer\": \"It has short sleeves.\"\n",
        "    }\n",
        "]"
      ],
      "metadata": {
        "id": "o1eCHR0yQRuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3.2 LLM Generated Examples\n",
        "\n",
        "Use an LLM to generate examples.\n",
        "\n",
        "*Q: how do we know that it is reliable? Does it need to be a better (more expensive) model, like GPT4? Surely we cannot use the same we used in the RAG to generate tests for its own performance!*"
      ],
      "metadata": {
        "id": "hCZeIj46RXuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation.qa import QAGenerateChain"
      ],
      "metadata": {
        "id": "7_-OlocAQKjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_gen_chain = QAGenerateChain.from_llm(OpenAI(model=llm_model_name, openai_api_key= OPEN_AI_KEY))"
      ],
      "metadata": {
        "id": "KRR-3Zz6728b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_examples = example_gen_chain.apply_and_parse(\n",
        "    [{\"doc\": t} for t in data[:5]]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdwf8HqR1HgO",
        "outputId": "d0d9daf1-5615-45f6-dbe3-7e750c426c31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain/chains/llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_examples[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoCopyBq78iL",
        "outputId": "2da2d0ab-1ec8-4d6e-a807-ee733479f452"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'qa_pairs': {'query': 'What is the name of the top described in the document?',\n",
              "  'answer': 'The name of the top is \"Classic Varsity Top.\"'}}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhtMse9E8aGl",
        "outputId": "db3e799a-ff6a-4918-cafd-fed6f23c0040"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content=': 1\\nname: Classic Varsity Top\\ndescription: Womens casual varsity top, This grey and black buttoned top is a sport-inspired piece complete with an embroidered letter.', metadata={'source': '/content/drive/MyDrive/notes/week11/apparel_modified.csv', 'row': 1})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_examples = [x['qa_pairs'] for x in new_examples] # make the examples fromat match [{'query': , 'answer': }]"
      ],
      "metadata": {
        "id": "fD0pvoGdc3GD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we combine the examples together\n",
        "examples = hardcoded_examples + new_examples\n",
        "len(examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QUertyqX8BaT",
        "outputId": "d20af50c-2c07-4b8a-9f1e-6a70a6b151a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.4 Manual Evaluation:\n",
        "evaluation by eye"
      ],
      "metadata": {
        "id": "6iJ6U_sQ9Z5H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(examples[0][\"query\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "id": "etDyju4Q9VNi",
        "outputId": "b13795a1-874b-436e-c84c-0a615d7ff398"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Yes, the Zipped Jacket has an outer zipped chestpocket for easy storage.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples[0]['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_gbrcZWg9gba",
        "outputId": "f82b7022-ba16-4fb0-ef00-d555892b34bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Yes.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The answer is correct!"
      ],
      "metadata": {
        "id": "mmkyVNSY9n7p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using debug mode: this way we see which docs were retrieved, what prompt was used in generation .. etc\n",
        "import langchain\n",
        "langchain.debug = True"
      ],
      "metadata": {
        "id": "Vr4yAMaL9mid"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "qa.run(examples[1][\"query\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 976
        },
        "id": "W453Lz9Fau3j",
        "outputId": "bd85f8bf-ded2-4c19-9ce8-23287b2fbc6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"query\": \"What kind of sleeves does the Silk Summer Top have?\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
            "\u001b[0m[inputs]\n",
            "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
            "\u001b[0m{\n",
            "  \"question\": \"What kind of sleeves does the Silk Summer Top have?\",\n",
            "  \"context\": \": 13\\nname: Silk Summer Top\\ndescription: Silk womens top with short sleeves and number pattern.<<<<>>>>>: 14\\nname: Long Sleeve Cotton Top\\ndescription: Black cotton womens top, with long sleeves, no collar and a thick hem.<<<<>>>>>: 5\\nname: Floral White Top\\ndescription: Stylish sleeveless white top with a floral pattern.<<<<>>>>>: 6\\nname: Striped Silk Blouse\\ndescription: Ultra-stylish black and red striped silk blouse with buckle collar and matching button pants.\"\n",
            "}\n",
            "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:OpenAI] Entering LLM run with input:\n",
            "\u001b[0m{\n",
            "  \"prompts\": [\n",
            "    \"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.\\n\\n: 13\\nname: Silk Summer Top\\ndescription: Silk womens top with short sleeves and number pattern.<<<<>>>>>: 14\\nname: Long Sleeve Cotton Top\\ndescription: Black cotton womens top, with long sleeves, no collar and a thick hem.<<<<>>>>>: 5\\nname: Floral White Top\\ndescription: Stylish sleeveless white top with a floral pattern.<<<<>>>>>: 6\\nname: Striped Silk Blouse\\ndescription: Ultra-stylish black and red striped silk blouse with buckle collar and matching button pants.\\n\\nQuestion: What kind of sleeves does the Silk Summer Top have?\\nHelpful Answer:\"\n",
            "  ]\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:OpenAI] [245ms] Exiting LLM run with output:\n",
            "\u001b[0m{\n",
            "  \"generations\": [\n",
            "    [\n",
            "      {\n",
            "        \"text\": \" Short sleeves.\",\n",
            "        \"generation_info\": {\n",
            "          \"finish_reason\": \"stop\",\n",
            "          \"logprobs\": null\n",
            "        },\n",
            "        \"type\": \"Generation\"\n",
            "      }\n",
            "    ]\n",
            "  ],\n",
            "  \"llm_output\": {\n",
            "    \"token_usage\": {\n",
            "      \"total_tokens\": 171,\n",
            "      \"prompt_tokens\": 168,\n",
            "      \"completion_tokens\": 3\n",
            "    },\n",
            "    \"model_name\": \"gpt-3.5-turbo-instruct\"\n",
            "  },\n",
            "  \"run\": null\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [251ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"text\": \" Short sleeves.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [263ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"output_text\": \" Short sleeves.\"\n",
            "}\n",
            "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [436ms] Exiting Chain run with output:\n",
            "\u001b[0m{\n",
            "  \"result\": \" Short sleeves.\"\n",
            "}\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' Short sleeves.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "examples[1]['answer']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "lNqzLdc0ayri",
        "outputId": "1ec5dbf6-1875-4040-c8b9-50496f7aecd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'It has short sleeves.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langchain.debug = False"
      ],
      "metadata": {
        "id": "7vnOu008biOA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.5 LLM assisted evaluation\n",
        "\n",
        "use an LLM to judge the answers"
      ],
      "metadata": {
        "id": "c1d0nHO6b30q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loop through all the examples\n",
        "\n",
        "predictions = qa.apply(examples)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbVWEbnCbz91",
        "outputId": "86518ada-513b-4291-91ca-faacdbe5e5c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wgGhSJoeecW8",
        "outputId": "7b0e84fc-16a2-47fd-9e27-59e8c61d5176"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'query': 'Does the Zipped Jacket have a chestpocket?',\n",
              " 'answer': 'Yes.',\n",
              " 'result': ' Yes, the Zipped Jacket has an outer zipped chestpocket for easy storage.'}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import Langchain specialized LLM for judging QA\n",
        "from langchain.evaluation.qa import QAEvalChain\n",
        "\n",
        "llm = OpenAI(temperature=0, model=llm_model_name, openai_api_key = OPEN_AI_KEY)\n",
        "eval_chain = QAEvalChain.from_llm(llm)"
      ],
      "metadata": {
        "id": "rBEwAUD_cEWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs = eval_chain.evaluate(examples, predictions)"
      ],
      "metadata": {
        "id": "_2yPC7WYd8a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "graded_outputs[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqBeKUMTenYJ",
        "outputId": "c9579cda-f1d4-4015-e80e-a40504f7601e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'results': ' CORRECT'}"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# lets see what is going on for each example\n",
        "\n",
        "for i, eg in enumerate(examples):\n",
        "  print(f\"Example {i}:\")\n",
        "  print(\"Question: \" + predictions[i]['query'])\n",
        "  print(\"Real Answer: \" + predictions[i]['answer'])\n",
        "  print(\"Predicted Answer: \" + predictions[i]['result'])\n",
        "  print(\"Predicted Grade: \" + graded_outputs[i]['results'])\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTEuz_F7eBsL",
        "outputId": "41ddc5d0-58b9-4a02-f15e-2732f460de74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example 0:\n",
            "Question: Does the Zipped Jacket have a chestpocket?\n",
            "Real Answer: Yes.\n",
            "Predicted Answer:  Yes, the Zipped Jacket has an outer zipped chestpocket for easy storage.\n",
            "Predicted Grade:  CORRECT\n",
            "\n",
            "Example 1:\n",
            "Question: What kind of sleeves does the Silk Summer Top have?\n",
            "Real Answer: It has short sleeves.\n",
            "Predicted Answer:  Short sleeves.\n",
            "Predicted Grade:  CORRECT\n",
            "\n",
            "Example 2:\n",
            "Question: What is the name of the shirt described in the document?\n",
            "Real Answer: The name of the shirt is Ocean Blue Shirt.\n",
            "Predicted Answer:  The name of the shirt is Red Sports Tee.\n",
            "Predicted Grade:  INCORRECT\n",
            "\n",
            "Example 3:\n",
            "Question: What is the name of the top described in the document?\n",
            "Real Answer: The name of the top is \"Classic Varsity Top.\"\n",
            "Predicted Answer:  The name of the top is \"Striped Skirt and Top\".\n",
            "Predicted Grade:  INCORRECT\n",
            "\n",
            "Example 4:\n",
            "Question: What is the name of the jumper described in the document?\n",
            "Real Answer: The name of the jumper is \"Yellow Wool Jumper\".\n",
            "Predicted Answer:  The name of the jumper is Yellow Wool Jumper.\n",
            "Predicted Grade:  CORRECT\n",
            "\n",
            "Example 5:\n",
            "Question: What is the name of the top described in this document?\n",
            "Real Answer: The name of the top is \"Floral White Top\".\n",
            "Predicted Answer:  The name of the top is Floral White Top.\n",
            "Predicted Grade:  CORRECT\n",
            "\n",
            "Example 6:\n",
            "Question: What is the name of the blouse in this document?\n",
            "Real Answer: The name of the blouse is \"Striped Silk Blouse\".\n",
            "Predicted Answer:  The name of the blouse is Striped Silk Blouse.\n",
            "Predicted Grade:  CORRECT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our pipeline got two questions wrong, but that basically because they where terrible questions."
      ],
      "metadata": {
        "id": "-WsFpAM2e58m"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VTEKFZQ9elce"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}